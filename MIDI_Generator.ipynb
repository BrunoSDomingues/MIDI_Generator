{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "561ad5f3",
   "metadata": {},
   "source": [
    "# Gerador de Músicas MIDI\n",
    "\n",
    "O projeto consiste em realizar um estudo no qual serão geradas músicas sem intervenção humana. Para tal, utilizou-se de músicas clássicas de Chopin como dataset e um modelo de Deep Learning.\n",
    "\n",
    "## Deep Learning - Uma breve introdução\n",
    "\n",
    "O Deep Learning é um algoritmo de Machine Learning, no qual são utilizadas redes neurais que buscam \"aprender\" de forma similar ao comportamento humano.\n",
    "\n",
    "Uma forma simples de entender é imaginar uma criança aprendendo a reconhecer objetos. A criança pode apontar para um objeto e dizer que é um carro. Dado isto, o pai/a mãe da criança pode reagir de duas maneiras: confirmar que o objeto que a criança apontou é um carro, ou falar \"Não, isto é um jarro\". Ao receber feedback suficiente, a criança começa a internalizar as características de cada objeto e cria um modelo mental que ajuda ela a reconhecer os diferentes objetos. Este modelo depende de uma comunicação efetiva entre os neurônios, transmitindo diferentes sinais e gerando este modelo complexo e hierárquico baseado no feedback recebido.\n",
    "\n",
    "O Deep Learning busca replicar este comportamento, criando um modelo no qual não é necessário entender cada etapa e decisão feita devido à complexidade e profundidade deste. Para criar o modelo, são utilizadas múltiplas camadas de \"neurônios digitais\", que vão repassando o aprendizado de camada em camada.\n",
    "\n",
    "Inicialmente, o modelo é alimentado com os dados a serem utilizados, e este tenta prever os dados, sem nenhuma intervenção. As previsões iniciais irão ser completamente (ou em sua maior parte) incorretas, mas conforme o modelo recebe feedback de suas previões, ele ajusta a comunicação entre seus \"neurônios\" até ser capaz de gerar previsões mais acuradas.\n",
    "\n",
    "Existem diversos modelos de Deep Learning, e para o desenvolvimentod este projeto, irá ser utilizado o modelo de WaveNet.\n",
    "\n",
    "## WaveNet\n",
    "\n",
    "O WaveNet é um modelo de Deep Learning para áudios \"crus\" desenvolvido pelo Google DeepMind. Ele é chamado de \"generative model\", pois tem como objetivo gerar novos samples a partir da distribuição original dos dados. Ele atua de forma similar aos modelos de linguagem utilizados em NLP.\n",
    "\n",
    "### Treinando o WaveNet\n",
    "\n",
    "Para treinar o modelo de WaveNet, utiliza-se um trecho de uma onda crua de áudio (no caso, a onda de áudio no domínio do tempo) como input. Uma onda de áudio no domínio do tempo é representada na forma de diferente valores de amplitude em diferentes intervalos de tempo, como é possível visualizar no gif abaixo.\n",
    "\n",
    "![Onda de áudio no domínio do tempo](https://jvbalen.github.io/figs/wavenet.gif)\n",
    "\n",
    "A partir da sequência de valores de amplitude, o WaveNet tenta prever qual valor de amplitude vem em seguida. Neste caso, o output depende somente das informações prévias, e não das informações que ainda serão obtidas, o que classifica este modelo como autoregressivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1f4e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System libraries\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from itertools import tee\n",
    "\n",
    "# Numpy for arrays and matplotlib for notes histogram\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Music21 library for MIDI reading and creating\n",
    "import music21 as m21\n",
    "from music21.note import Note\n",
    "from music21.chord import Chord\n",
    "\n",
    "# sklearn to split train and test \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0afc42f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_folder_path = \"chopin/\"\n",
    "threaded = True # Enable threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "624bebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = True\n",
    "\n",
    "if train_model:\n",
    "    # keras to train the model\n",
    "    import keras.backend as kb\n",
    "    import keras.callbacks as kc\n",
    "    import keras.layers as kl\n",
    "    import keras.models as km\n",
    "else:\n",
    "    # keras to load the model only\n",
    "    from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c19ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(file):   \n",
    "    notes = []\n",
    "    \n",
    "    # Parsing the MIDI file\n",
    "    midi = m21.converter.parse(file)\n",
    "  \n",
    "    # Partition by instrument\n",
    "    partition = m21.instrument.partitionByInstrument(midi)\n",
    "\n",
    "    # Looping over all the instruments\n",
    "    for part in partition.parts:\n",
    "        # Select only the piano\n",
    "        if 'Piano' not in str(part):\n",
    "            continue\n",
    "\n",
    "        # Checking if it is a note or a chord\n",
    "        for element in part.recurse():\n",
    "            if isinstance(element, Note):\n",
    "                notes.append(str(element.pitch))\n",
    "\n",
    "            elif isinstance(element, Chord):\n",
    "                notes.append('.'.join(map(str, element.normalOrder)))\n",
    "\n",
    "    return np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d01016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2002 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 1997 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2002 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2002 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=0, channel=None, data=b'Et\\xfcde Opus 25, No. 11'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=0, channel=None, data=b'Sturmet\\xfcde'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2003 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2002 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 1997 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 1997 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2003 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2002 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2003 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 1999 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=0, channel=None, data=b'Et\\xfcde Opus 10 No. 5'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=0, channel=None, data=b'Schwarze-Tasten-Et\\xfcde'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=0, channel=None, data=b'Et\\xfcde Nr. 12'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 1999 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2003 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 1999 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2002 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 1997 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 1997 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=0, channel=None, data=b'Et\\xfcde Opus 10 No. 5'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2003 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 1999 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2002 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2002 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2003 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2002 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2003 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2003 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2002 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2003 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 1997 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2002 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 1997 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "files = (p for p in Path(extracted_folder_path).rglob(\"*\") if p.is_file() and p.suffix == \".mid\")\n",
    "\n",
    "if threaded:\n",
    "    from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "    with ProcessPoolExecutor() as pool:\n",
    "        notes_list = list(pool.map(read_midi, files))\n",
    "else:\n",
    "    notes_list = list(map(read_midi, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb61e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening notes_list\n",
    "notes_f = np.concatenate(notes_list).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b999f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique notes: 397\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 319
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get frequency of each note\n",
    "unique_notes, counts = np.unique(notes_f, return_counts=True)\n",
    "\n",
    "print(f\"Number of unique notes: {len(unique_notes)}\")\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(counts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "781ce82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the most frequent notes\n",
    "frequent_notes = frozenset(unique_notes[counts >= 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d6ca8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert note to int and vice-versa\n",
    "\n",
    "# Use tee to guarantee the iterators are the same\n",
    "enum_it, rev_enum_it = tee(enumerate(frequent_notes))\n",
    "\n",
    "# Helper functions\n",
    "d_int_to_note = dict(enum_it)\n",
    "int_to_note = lambda idx: d_int_to_note[idx]\n",
    "\n",
    "d_note_to_int = {note: idx for idx, note in rev_enum_it}\n",
    "note_to_int = lambda idx: d_note_to_int[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d4c821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_music = []\n",
    "\n",
    "# Adding the most frequent notes\n",
    "for notes in notes_list:\n",
    "    new_music.append([d_note_to_int[note] for note in notes if note in frequent_notes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5690ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = 32\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for note in new_music:\n",
    "    for start in range(len(note) - n_timesteps):\n",
    "        end = start + n_timesteps\n",
    "        X.append(note[start:end])  # Input\n",
    "        y.append(note[end])        # Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dbfed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(np.array(X), np.array(y), test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3459fe2",
   "metadata": {},
   "source": [
    "### Arquitetura WaveNet\n",
    "\n",
    "Os pilares da arquitetura WaveNet estão em suas camadas de rede neural, as quais são chamadas de \"Causal Diluted 1D Convolution layers\". Mas o que significa isso? Para tal, devemos ir por partes. \n",
    "\n",
    "O primeiro conceito importante é o conceito de \"convolution\": é uma operação matemática na qual é feita uma forma de combinação entre 2 funções. Um exemplo disto é em visão computacional, onde pode ser feita uma combinação linear de uma imagem com um kernel, resultando em uma imagem que possui um filtro. Estendendo este conceito, podemos seguir para a \"1D Convolution\". Como o nome diz, ela é unidimensional, e nela o kernel/filtro se move em apenas uma direção de modo a gerar um output. A imagem abaixo mostra como um kernel (representado pelos blocos verdes) e um input (representado pelos blocos amarelos) formam um output (representado pelos blocos roxos).\n",
    "\n",
    "![1D Convolution](https://www.researchgate.net/publication/324177888/figure/fig3/AS:611641670504448@1522838146178/Calculations-involved-in-a-1D-convolution-operation.png)\n",
    "\n",
    "O output depende do tamanho do kernel, do padding, e do stride. Para este estudo, o mais importante é o padding. O padding é a ideia de possivelmente adicionar zeros à esquerda ou à direita do input de modo a gerar um output com o mesmo tamanho do input. Em 1D Convolution, existem três opções de padding:\n",
    "\n",
    "- `valid`: sem padding algum;\n",
    "- `same`: padding simétrico (mesma quantidade de zeros na esquerda e na direita);\n",
    "- `causal`: adiciona-se zeros **somente** à esquerda do input;\n",
    "\n",
    "Para nosso estudo, o padding será definido como `causal`, pois assim podemos garantir que nosso modelo depende apenas do dado atual e de dados anteriores, nunca de dados futuros (explicando assim o conceito de Causal 1D Convolution).\n",
    "\n",
    "Por fim, resta o conceito de Dilated Causal 1D Convolution. O \"Dilated\" consiste em \"furos\" ou espaços vazios entre os valores do kernel, de modo intercalado. O número de espaços depende do dilation rate do kernel, que define o chamado reception field da rede (quantidade de inputs que diretamente afetam o output). Para um kernel de tamanho `k` e um dilation rate de tamanho `d`, a nossa camada possui `d-1` espaços entre cada valor do kernel. No gif abaixo é possível ver um exemplo de kernel de tamanho 3x3 com dilation rate de 2 em um input de tamanho 7x7, o que gera um reception field de tamanho 5x5.\n",
    "\n",
    "![Dilated 1D Causal Convolution](https://miro.medium.com/max/593/0*oX5IPr7TlVM2NpEU.gif)\n",
    "\n",
    "Para agilizar a convergênca dos dados existem também as conexões Residual e Skip, mas estas não serão utilizadas neste estudo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "074b4163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 32, 100)           16900     \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 32, 64)            19264     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 64)            0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 16, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 16, 128)           24704     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 8, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 8, 256)            98560     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 4, 256)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 256)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 169)               43433     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 268,653\n",
      "Trainable params: 268,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 10:48:03.812603: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-08 10:48:03.814602: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "if train_model:\n",
    "    kb.clear_session()\n",
    "    model = km.Sequential()\n",
    "\n",
    "    # TODO: Validate x.unique() = frequent_notes\n",
    "    model.add(kl.Embedding(len(frequent_notes), 100, input_length=32, trainable=True)) \n",
    "\n",
    "    model.add(kl.Conv1D(64, 3, padding='causal',activation='relu'))\n",
    "    model.add(kl.Dropout(0.2))\n",
    "    model.add(kl.MaxPool1D(2))\n",
    "\n",
    "    model.add(kl.Conv1D(128, 3, activation='relu', dilation_rate=2, padding='causal'))\n",
    "    model.add(kl.Dropout(0.2))\n",
    "    model.add(kl.MaxPool1D(2))\n",
    "\n",
    "    model.add(kl.Conv1D(256, 3, activation='relu', dilation_rate=4, padding='causal'))\n",
    "    model.add(kl.Dropout(0.2))\n",
    "    model.add(kl.MaxPool1D(2))\n",
    "\n",
    "    model.add(kl.GlobalMaxPool1D())\n",
    "\n",
    "    model.add(kl.Dense(256, activation='relu'))\n",
    "    # TODO: Validate y.unique() = frequent_notes\n",
    "    model.add(kl.Dense(len(frequent_notes), activation='softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c007ea7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 4.5264\n",
      "Epoch 00001: val_loss improved from inf to 4.31399, saving model to model.h5\n",
      "298/298 [==============================] - 24s 79ms/step - loss: 4.5264 - val_loss: 4.3140\n",
      "Epoch 2/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 4.0785\n",
      "Epoch 00002: val_loss improved from 4.31399 to 4.12130, saving model to model.h5\n",
      "298/298 [==============================] - 25s 84ms/step - loss: 4.0785 - val_loss: 4.1213\n",
      "Epoch 3/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.8813\n",
      "Epoch 00003: val_loss improved from 4.12130 to 3.93952, saving model to model.h5\n",
      "298/298 [==============================] - 25s 84ms/step - loss: 3.8813 - val_loss: 3.9395\n",
      "Epoch 4/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.7559\n",
      "Epoch 00004: val_loss improved from 3.93952 to 3.87370, saving model to model.h5\n",
      "298/298 [==============================] - 25s 85ms/step - loss: 3.7559 - val_loss: 3.8737\n",
      "Epoch 5/50\n",
      "297/298 [============================>.] - ETA: 0s - loss: 3.6590\n",
      "Epoch 00005: val_loss improved from 3.87370 to 3.78883, saving model to model.h5\n",
      "298/298 [==============================] - 24s 80ms/step - loss: 3.6586 - val_loss: 3.7888\n",
      "Epoch 6/50\n",
      "297/298 [============================>.] - ETA: 0s - loss: 3.5723\n",
      "Epoch 00006: val_loss improved from 3.78883 to 3.75058, saving model to model.h5\n",
      "298/298 [==============================] - 23s 76ms/step - loss: 3.5721 - val_loss: 3.7506\n",
      "Epoch 7/50\n",
      "297/298 [============================>.] - ETA: 0s - loss: 3.4948\n",
      "Epoch 00007: val_loss improved from 3.75058 to 3.65521, saving model to model.h5\n",
      "298/298 [==============================] - 24s 81ms/step - loss: 3.4956 - val_loss: 3.6552\n",
      "Epoch 8/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.4229\n",
      "Epoch 00008: val_loss improved from 3.65521 to 3.63088, saving model to model.h5\n",
      "298/298 [==============================] - 26s 86ms/step - loss: 3.4229 - val_loss: 3.6309\n",
      "Epoch 9/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.3592\n",
      "Epoch 00009: val_loss improved from 3.63088 to 3.58275, saving model to model.h5\n",
      "298/298 [==============================] - 27s 90ms/step - loss: 3.3592 - val_loss: 3.5827\n",
      "Epoch 10/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.2972\n",
      "Epoch 00010: val_loss improved from 3.58275 to 3.54749, saving model to model.h5\n",
      "298/298 [==============================] - 26s 86ms/step - loss: 3.2972 - val_loss: 3.5475\n",
      "Epoch 11/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.2453\n",
      "Epoch 00011: val_loss improved from 3.54749 to 3.48267, saving model to model.h5\n",
      "298/298 [==============================] - 24s 82ms/step - loss: 3.2453 - val_loss: 3.4827\n",
      "Epoch 12/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.1887\n",
      "Epoch 00012: val_loss improved from 3.48267 to 3.46491, saving model to model.h5\n",
      "298/298 [==============================] - 25s 85ms/step - loss: 3.1887 - val_loss: 3.4649\n",
      "Epoch 13/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.1475\n",
      "Epoch 00013: val_loss improved from 3.46491 to 3.44255, saving model to model.h5\n",
      "298/298 [==============================] - 27s 89ms/step - loss: 3.1475 - val_loss: 3.4426\n",
      "Epoch 14/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.0969\n",
      "Epoch 00014: val_loss improved from 3.44255 to 3.41519, saving model to model.h5\n",
      "298/298 [==============================] - 25s 85ms/step - loss: 3.0969 - val_loss: 3.4152\n",
      "Epoch 15/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.0634\n",
      "Epoch 00015: val_loss improved from 3.41519 to 3.40329, saving model to model.h5\n",
      "298/298 [==============================] - 26s 87ms/step - loss: 3.0634 - val_loss: 3.4033\n",
      "Epoch 16/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.0279\n",
      "Epoch 00016: val_loss improved from 3.40329 to 3.36615, saving model to model.h5\n",
      "298/298 [==============================] - 26s 88ms/step - loss: 3.0279 - val_loss: 3.3661\n",
      "Epoch 17/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.9898\n",
      "Epoch 00017: val_loss improved from 3.36615 to 3.34537, saving model to model.h5\n",
      "298/298 [==============================] - 26s 87ms/step - loss: 2.9898 - val_loss: 3.3454\n",
      "Epoch 18/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.9590\n",
      "Epoch 00018: val_loss improved from 3.34537 to 3.34090, saving model to model.h5\n",
      "298/298 [==============================] - 26s 89ms/step - loss: 2.9590 - val_loss: 3.3409\n",
      "Epoch 19/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.9238\n",
      "Epoch 00019: val_loss improved from 3.34090 to 3.33095, saving model to model.h5\n",
      "298/298 [==============================] - 26s 86ms/step - loss: 2.9238 - val_loss: 3.3309\n",
      "Epoch 20/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.8942\n",
      "Epoch 00020: val_loss improved from 3.33095 to 3.30159, saving model to model.h5\n",
      "298/298 [==============================] - 26s 86ms/step - loss: 2.8942 - val_loss: 3.3016\n",
      "Epoch 21/50\n",
      "297/298 [============================>.] - ETA: 0s - loss: 2.8672\n",
      "Epoch 00021: val_loss improved from 3.30159 to 3.29273, saving model to model.h5\n",
      "298/298 [==============================] - 26s 88ms/step - loss: 2.8672 - val_loss: 3.2927\n",
      "Epoch 22/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.8454\n",
      "Epoch 00022: val_loss improved from 3.29273 to 3.27271, saving model to model.h5\n",
      "298/298 [==============================] - 25s 83ms/step - loss: 2.8454 - val_loss: 3.2727\n",
      "Epoch 23/50\n",
      "297/298 [============================>.] - ETA: 0s - loss: 2.8111\n",
      "Epoch 00023: val_loss improved from 3.27271 to 3.26465, saving model to model.h5\n",
      "298/298 [==============================] - 24s 80ms/step - loss: 2.8111 - val_loss: 3.2646\n",
      "Epoch 24/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.7905\n",
      "Epoch 00024: val_loss improved from 3.26465 to 3.24221, saving model to model.h5\n",
      "298/298 [==============================] - 26s 89ms/step - loss: 2.7905 - val_loss: 3.2422\n",
      "Epoch 25/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.7656\n",
      "Epoch 00025: val_loss improved from 3.24221 to 3.24067, saving model to model.h5\n",
      "298/298 [==============================] - 27s 91ms/step - loss: 2.7656 - val_loss: 3.2407\n",
      "Epoch 26/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.7471\n",
      "Epoch 00026: val_loss improved from 3.24067 to 3.23425, saving model to model.h5\n",
      "298/298 [==============================] - 27s 92ms/step - loss: 2.7471 - val_loss: 3.2343\n",
      "Epoch 27/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.7266\n",
      "Epoch 00027: val_loss improved from 3.23425 to 3.23369, saving model to model.h5\n",
      "298/298 [==============================] - 25s 85ms/step - loss: 2.7266 - val_loss: 3.2337\n",
      "Epoch 28/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.7012\n",
      "Epoch 00028: val_loss improved from 3.23369 to 3.21296, saving model to model.h5\n",
      "298/298 [==============================] - 25s 84ms/step - loss: 2.7012 - val_loss: 3.2130\n",
      "Epoch 29/50\n",
      "297/298 [============================>.] - ETA: 0s - loss: 2.6826\n",
      "Epoch 00029: val_loss improved from 3.21296 to 3.20417, saving model to model.h5\n",
      "298/298 [==============================] - 27s 92ms/step - loss: 2.6828 - val_loss: 3.2042\n",
      "Epoch 30/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.6731\n",
      "Epoch 00030: val_loss improved from 3.20417 to 3.19381, saving model to model.h5\n",
      "298/298 [==============================] - 28s 93ms/step - loss: 2.6731 - val_loss: 3.1938\n",
      "Epoch 31/50\n",
      "297/298 [============================>.] - ETA: 0s - loss: 2.6475\n",
      "Epoch 00031: val_loss improved from 3.19381 to 3.18973, saving model to model.h5\n",
      "298/298 [==============================] - 25s 84ms/step - loss: 2.6470 - val_loss: 3.1897\n",
      "Epoch 32/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.6306\n",
      "Epoch 00032: val_loss improved from 3.18973 to 3.18433, saving model to model.h5\n",
      "298/298 [==============================] - 28s 93ms/step - loss: 2.6306 - val_loss: 3.1843\n",
      "Epoch 33/50\n",
      "297/298 [============================>.] - ETA: 0s - loss: 2.6222\n",
      "Epoch 00033: val_loss improved from 3.18433 to 3.17809, saving model to model.h5\n",
      "298/298 [==============================] - 27s 92ms/step - loss: 2.6224 - val_loss: 3.1781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.6022\n",
      "Epoch 00034: val_loss improved from 3.17809 to 3.17152, saving model to model.h5\n",
      "298/298 [==============================] - 26s 87ms/step - loss: 2.6022 - val_loss: 3.1715\n",
      "Epoch 35/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.5924\n",
      "Epoch 00035: val_loss did not improve from 3.17152\n",
      "298/298 [==============================] - 25s 83ms/step - loss: 2.5924 - val_loss: 3.1721\n",
      "Epoch 36/50\n",
      "297/298 [============================>.] - ETA: 0s - loss: 2.5802\n",
      "Epoch 00036: val_loss improved from 3.17152 to 3.16906, saving model to model.h5\n",
      "298/298 [==============================] - 25s 85ms/step - loss: 2.5805 - val_loss: 3.1691\n",
      "Epoch 37/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.5692\n",
      "Epoch 00037: val_loss improved from 3.16906 to 3.15160, saving model to model.h5\n",
      "298/298 [==============================] - 25s 85ms/step - loss: 2.5692 - val_loss: 3.1516\n",
      "Epoch 38/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.5487\n",
      "Epoch 00038: val_loss did not improve from 3.15160\n",
      "298/298 [==============================] - 25s 84ms/step - loss: 2.5487 - val_loss: 3.1522\n",
      "Epoch 39/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.5401\n",
      "Epoch 00039: val_loss improved from 3.15160 to 3.14831, saving model to model.h5\n",
      "298/298 [==============================] - 25s 84ms/step - loss: 2.5401 - val_loss: 3.1483\n",
      "Epoch 40/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.5271\n",
      "Epoch 00040: val_loss did not improve from 3.14831\n",
      "298/298 [==============================] - 24s 82ms/step - loss: 2.5271 - val_loss: 3.1483\n",
      "Epoch 41/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.5089\n",
      "Epoch 00041: val_loss did not improve from 3.14831\n",
      "298/298 [==============================] - 26s 88ms/step - loss: 2.5089 - val_loss: 3.1489\n",
      "Epoch 42/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.5063\n",
      "Epoch 00042: val_loss improved from 3.14831 to 3.14666, saving model to model.h5\n",
      "298/298 [==============================] - 26s 88ms/step - loss: 2.5063 - val_loss: 3.1467\n",
      "Epoch 43/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.4882\n",
      "Epoch 00043: val_loss improved from 3.14666 to 3.13176, saving model to model.h5\n",
      "298/298 [==============================] - 26s 86ms/step - loss: 2.4882 - val_loss: 3.1318\n",
      "Epoch 44/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.4759\n",
      "Epoch 00044: val_loss improved from 3.13176 to 3.13129, saving model to model.h5\n",
      "298/298 [==============================] - 26s 87ms/step - loss: 2.4759 - val_loss: 3.1313\n",
      "Epoch 45/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.4805\n",
      "Epoch 00045: val_loss did not improve from 3.13129\n",
      "298/298 [==============================] - 26s 87ms/step - loss: 2.4805 - val_loss: 3.1354\n",
      "Epoch 46/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.4636\n",
      "Epoch 00046: val_loss improved from 3.13129 to 3.12586, saving model to model.h5\n",
      "298/298 [==============================] - 36s 121ms/step - loss: 2.4636 - val_loss: 3.1259\n",
      "Epoch 47/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.4524\n",
      "Epoch 00047: val_loss did not improve from 3.12586\n",
      "298/298 [==============================] - 41s 139ms/step - loss: 2.4524 - val_loss: 3.1372\n",
      "Epoch 48/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.4368\n",
      "Epoch 00048: val_loss did not improve from 3.12586\n",
      "298/298 [==============================] - 32s 107ms/step - loss: 2.4368 - val_loss: 3.1295\n",
      "Epoch 49/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.4413\n",
      "Epoch 00049: val_loss improved from 3.12586 to 3.11898, saving model to model.h5\n",
      "298/298 [==============================] - 31s 103ms/step - loss: 2.4413 - val_loss: 3.1190\n",
      "Epoch 50/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.4307\n",
      "Epoch 00050: val_loss improved from 3.11898 to 3.11836, saving model to model.h5\n",
      "298/298 [==============================] - 31s 104ms/step - loss: 2.4307 - val_loss: 3.1184\n"
     ]
    }
   ],
   "source": [
    "if train_model:\n",
    "    mc = kc.ModelCheckpoint('model.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "    history = model.fit(X_train, y_train, batch_size=128, epochs=50, validation_data=(X_val, y_val), verbose=1, callbacks=[mc])\n",
    "else:\n",
    "    model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3014ff90",
   "metadata": {},
   "source": [
    "### Gerando novas samples\n",
    "\n",
    "Para gerar uma música com samples anteriores, basta seguir a lógica abaixo:\n",
    "\n",
    "1. Selecionar um array com diferentes valores de samples como ponto de início\n",
    "2. O modelo calcula a distribuição de probabilidades de todas as samples\n",
    "3. O modelo obtém a sample com maior probabilidade e coloca ela no final do array\n",
    "4. Remove-se o primeiro elemento do array e reinsere-se o novo array como input\n",
    "5. Repetem-se os passos 2 a 4 por um número `n` de iterações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56d25d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53, 53, 53, 53, 53, 142, 1, 142, 1, 55]\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, X_val.shape[0] - 1)\n",
    "\n",
    "random_music = X_val[idx]\n",
    "predictions = []\n",
    "\n",
    "for i in range(10):\n",
    "    random_music = random_music.reshape(1, n_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred = np.argmax(prob, axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0], len(random_music[0]), y_pred)\n",
    "    random_music = random_music[1:]\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cda13245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting previously generated MIDI file, if any\n",
    "midi_file = \"music.mid\"\n",
    "Path(midi_file).unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15a280bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output, mf):\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for offset, pattern in enumerate(prediction_output):\n",
    "        # pattern is a chord\n",
    "        if '.' in pattern or pattern.isdigit():\n",
    "            notes = []\n",
    "            \n",
    "            for current_note in pattern.split('.'):\n",
    "                new_note = Note(int(current_note))\n",
    "                new_note.storedInstrument = m21.instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = m21.instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "    midi_stream = m21.stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp=mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5515b886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv336'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv336');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAAIsA/wMAAOAAQADAAIgAkEpaiACASgAAkEpaiACASgAAkEpaiACASgAAkEpaiACASgAAkEpaiACASgAAkD5aiACAPgAAkENaAJBGWgCQPlqIAIBDAACARgAAgD4AAJA+WogAgD4AAJBDWgCQRloAkD5aiACAQwAAgEYAAIA+AACQT1qIAIBPAIgA/y8A');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating MIDI file\n",
    "convert_to_midi(map(int_to_note, predictions), midi_file)\n",
    "\n",
    "# Shows MIDI in player\n",
    "# https://stackoverflow.com/questions/57021743/how-to-play-audio-inline-using-ipython-display-audio\n",
    "mf = m21.midi.MidiFile()\n",
    "mf.open(midi_file)\n",
    "mf.read()\n",
    "mf.close()\n",
    "s = m21.midi.translate.midiFileToStream(mf)\n",
    "s.show('midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6981ec55",
   "metadata": {},
   "source": [
    "## Conclusões\n",
    "\n",
    "O modelo foi capaz de gerar um trecho de notas musicais que remetem parcialmente a ideia de uma música. O uso de músicas de um mesmo compositor/artista e do mesmo gênero ajuda neste processo, pois não há o risco de confundir o modelo com muitos dados diferentes.\n",
    "\n",
    "No entanto, algumas notas se encontram com muita frequência, o que é presente no output. Em casos de músicas de input que não possuem muita variedade de notas/repetem muitas vezes certas notas, o modelo pode gerar algo que não soa como uma música.\n",
    "\n",
    "O ponto mais importante é que o conceito de música é subjetivo, e nem sempre utilizar as notas com maior probabilidade pode gerar uma música agradável ao ouvido humano.\n",
    "\n",
    "Para próximas iterações, pode-se aprimorar o modelo para utilizar mais de um instrumento para determinar as notas frequentes, de modo que eles interajam entre si. Pode-se também gerar alterações na lógica para considerar outros fatores além da alta probabilidade de uma nota musical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d8c523",
   "metadata": {},
   "source": [
    "## Bibliografia\n",
    "\n",
    "[Recurrent Neural Networks](https://www.slideshare.net/xavigiro/recurrent-neural-networks-2-d2l3-deep-learning-for-speech-and-language-upc-2017)  \n",
    "[WaveNet: A Generative Model for Raw Audio](https://arxiv.org/pdf/1609.03499.pdf)  \n",
    "[Keras API](https://keras.io/api/)  \n",
    "[music21 documentation](https://web.mit.edu/music21/doc/index.html)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
