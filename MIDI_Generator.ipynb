{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3459fe2",
   "metadata": {},
   "source": [
    "# Gerador de Músicas MIDI\n",
    "\n",
    "O projeto consiste em realizar um estudo no qual serão geradas músicas sem intervenção humana. Para tal, utilizou-se de músicas clássicas de Chopin como dataset e um modelo de Deep Learning.\n",
    "\n",
    "## Deep Learning - Uma breve introdução\n",
    "\n",
    "O Deep Learning é um algoritmo de Machine Learning, no qual são utilizadas redes neurais que buscam \"aprender\" de forma similar ao comportamento humano.\n",
    "\n",
    "Uma forma simples de entender é imaginar uma criança aprendendo a reconhecer objetos. A criança pode apontar para um objeto e dizer que é um carro. Dado isto, o pai/a mãe da criança pode reagir de duas maneiras: confirmar que o objeto que a criança apontou é um carro, ou falar \"Não, isto é um jarro\". Ao receber feedback suficiente, a criança começa a internalizar as características de cada objeto e cria um modelo mental que ajuda ela a reconhecer os diferentes objetos. Este modelo depende de uma comunicação efetiva entre os neurônios, transmitindo diferentes sinais e gerando este modelo complexo e hierárquico baseado no feedback recebido.\n",
    "\n",
    "O Deep Learning busca replicar este comportamento, criando um modelo no qual não é necessário entender cada etapa e decisão feita devido à complexidade e profundidade deste. Para criar o modelo, são utilizadas múltiplas camadas de \"neurônios digitais\", que vão repassando o aprendizado de camada em camada.\n",
    "\n",
    "Inicialmente, o modelo é alimentado com os dados a serem utilizados, e este tenta prever os dados, sem nenhuma intervenção. As previsões iniciais irão ser completamente (ou em sua maior parte) incorretas, mas conforme o modelo recebe feedback de suas previões, ele ajusta a comunicação entre seus \"neurônios\" até ser capaz de gerar previsões mais acuradas.\n",
    "\n",
    "Existem diversos modelos de Deep Learning, e para o desenvolvimentod este projeto, irá ser utilizado o modelo de WaveNet.\n",
    "\n",
    "## WaveNet\n",
    "\n",
    "O WaveNet é um modelo de Deep Learning para áudios \"crus\" desenvolvido pelo Google DeepMind. Ele é chamado de \"generative model\", pois tem como objetivo gerar novos samples a partir da distribuição original dos dados. Ele atua de forma similar aos modelos de linguagem utilizados em NLP.\n",
    "\n",
    "### Treinando o WaveNet\n",
    "\n",
    "Para treinar o modelo de WaveNet, utiliza-se um trecho de uma onda crua de áudio (no caso, a onda de áudio no domínio do tempo) como input. Uma onda de áudio no domínio do tempo é representada na forma de diferente valores de amplitude em diferentes intervalos de tempo, como é possível visualizar no gif abaixo.\n",
    "\n",
    "![Onda de áudio no domínio do tempo](https://jvbalen.github.io/figs/wavenet.gif)\n",
    "\n",
    "A partir da sequência de valores de amplitude, o WaveNet tenta prever qual valor de amplitude vem em seguida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1f4e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System libraries\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# Numpy for arrays and matplotlib for notes histogram\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Music21 library for MIDI reading and creating\n",
    "import music21 as m21\n",
    "from music21.note import Note\n",
    "from music21.chord import Chord\n",
    "\n",
    "# sklearn and keras for train/test of the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.backend as kb\n",
    "import keras.callbacks as kc\n",
    "import keras.layers as kl\n",
    "import keras.models as km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0c19ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(file):   \n",
    "    notes = []\n",
    "    \n",
    "    # Parsing the MIDI file\n",
    "    midi = m21.converter.parse(file)\n",
    "  \n",
    "    # Partition by instrument\n",
    "    partition = m21.instrument.partitionByInstrument(midi)\n",
    "\n",
    "    # Looping over all the instruments\n",
    "    for part in partition.parts:\n",
    "        # Select only the piano\n",
    "        if 'Piano' not in str(part):\n",
    "            continue\n",
    "\n",
    "        # Checking if it is a note or a chord\n",
    "        for element in part.recurse():\n",
    "            if isinstance(element, Note):\n",
    "                notes.append(str(element.pitch))\n",
    "\n",
    "            elif isinstance(element, Chord):\n",
    "                notes.append('.'.join(map(str, element.normalOrder)))\n",
    "\n",
    "    return np.array(notes)\n",
    "\n",
    "path = \"./chopin/\"\n",
    "files = [p for p in Path(path).rglob(\"*\") if p.is_file() and p.suffix == \".mid\"]\n",
    "\n",
    "notes_list = list(map(read_midi, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb61e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening notes_list\n",
    "notes_f = np.concatenate(notes_list).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b999f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique notes: 397\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 319
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#computing frequency of each note\n",
    "unique_notes, counts = np.unique(notes_f, return_counts=True)\n",
    "\n",
    "# No. of unique notes\n",
    "print(f\"Number of unique notes: {len(unique_notes)}\")\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(counts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "781ce82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the most frequent notes\n",
    "frequent_notes = frozenset(unique_notes[counts >= 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d4c821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_music = []\n",
    "\n",
    "# Adding the most frequent notes\n",
    "for notes in notes_list:\n",
    "    new_music.append([note_ for note_ in notes if note_ in frequent_notes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5690ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = 32\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# TODO: fix CDE\n",
    "\n",
    "for note_ in new_music:\n",
    "    for i in range(len(note_) - n_timesteps):\n",
    "        x.append(note_[i : i + n_timesteps])    # Input\n",
    "        y.append(note_[i + n_timesteps])        # Output\n",
    "        \n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5d6ca8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_x = list(set(x.ravel()))\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))\n",
    "\n",
    "# preparing input sequences\n",
    "x_seq = []\n",
    "\n",
    "for i in x:\n",
    "    temp = []\n",
    "    for j in i:\n",
    "        # assigning unique integer to every note\n",
    "        temp.append(x_note_to_int[j])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "056d4346",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq = np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c5c5e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq, y_seq, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "074b4163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 32, 100)           16900     \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 32, 64)            19264     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 64)            0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 16, 64)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 16, 128)           24704     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 8, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 8, 256)            98560     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 256)            0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 4, 256)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 256)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 169)               43433     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 268,653\n",
      "Trainable params: 268,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kb.clear_session()\n",
    "model = km.Sequential()\n",
    "    \n",
    "# embedding layer\n",
    "model.add(kl.Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
    "\n",
    "model.add(kl.Conv1D(64,3, padding='causal',activation='relu'))\n",
    "model.add(kl.Dropout(0.2))\n",
    "model.add(kl.MaxPool1D(2))\n",
    "    \n",
    "model.add(kl.Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(kl.Dropout(0.2))\n",
    "model.add(kl.MaxPool1D(2))\n",
    "\n",
    "model.add(kl.Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(kl.Dropout(0.2))\n",
    "model.add(kl.MaxPool1D(2))\n",
    "          \n",
    "model.add(kl.GlobalMaxPool1D())\n",
    "    \n",
    "model.add(kl.Dense(256, activation='relu'))\n",
    "model.add(kl.Dense(len(unique_y), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c007ea7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 4.5279\n",
      "Epoch 00001: val_loss improved from inf to 4.35146, saving model to best_model.h5\n",
      "298/298 [==============================] - 32s 107ms/step - loss: 4.5279 - val_loss: 4.3515\n",
      "Epoch 2/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 4.0794\n",
      "Epoch 00002: val_loss improved from 4.35146 to 4.08812, saving model to best_model.h5\n",
      "298/298 [==============================] - 31s 105ms/step - loss: 4.0794 - val_loss: 4.0881\n",
      "Epoch 3/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.8891\n",
      "Epoch 00003: val_loss improved from 4.08812 to 3.98746, saving model to best_model.h5\n",
      "298/298 [==============================] - 32s 108ms/step - loss: 3.8891 - val_loss: 3.9875\n",
      "Epoch 4/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.7597\n",
      "Epoch 00004: val_loss improved from 3.98746 to 3.91190, saving model to best_model.h5\n",
      "298/298 [==============================] - 32s 107ms/step - loss: 3.7597 - val_loss: 3.9119\n",
      "Epoch 5/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.6624\n",
      "Epoch 00005: val_loss improved from 3.91190 to 3.78452, saving model to best_model.h5\n",
      "298/298 [==============================] - 33s 111ms/step - loss: 3.6624 - val_loss: 3.7845\n",
      "Epoch 6/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.5766\n",
      "Epoch 00006: val_loss improved from 3.78452 to 3.72750, saving model to best_model.h5\n",
      "298/298 [==============================] - 33s 111ms/step - loss: 3.5766 - val_loss: 3.7275\n",
      "Epoch 7/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.5004\n",
      "Epoch 00007: val_loss improved from 3.72750 to 3.68103, saving model to best_model.h5\n",
      "298/298 [==============================] - 34s 114ms/step - loss: 3.5004 - val_loss: 3.6810\n",
      "Epoch 8/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.4345\n",
      "Epoch 00008: val_loss improved from 3.68103 to 3.61416, saving model to best_model.h5\n",
      "298/298 [==============================] - 33s 112ms/step - loss: 3.4345 - val_loss: 3.6142\n",
      "Epoch 9/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.3749\n",
      "Epoch 00009: val_loss did not improve from 3.61416\n",
      "298/298 [==============================] - 33s 111ms/step - loss: 3.3749 - val_loss: 3.6171\n",
      "Epoch 10/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.3244\n",
      "Epoch 00010: val_loss improved from 3.61416 to 3.55967, saving model to best_model.h5\n",
      "298/298 [==============================] - 34s 113ms/step - loss: 3.3244 - val_loss: 3.5597\n",
      "Epoch 11/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.2699\n",
      "Epoch 00011: val_loss improved from 3.55967 to 3.51831, saving model to best_model.h5\n",
      "298/298 [==============================] - 35s 118ms/step - loss: 3.2699 - val_loss: 3.5183\n",
      "Epoch 12/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.2202\n",
      "Epoch 00012: val_loss improved from 3.51831 to 3.49320, saving model to best_model.h5\n",
      "298/298 [==============================] - 33s 111ms/step - loss: 3.2202 - val_loss: 3.4932\n",
      "Epoch 13/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.1794\n",
      "Epoch 00013: val_loss improved from 3.49320 to 3.46203, saving model to best_model.h5\n",
      "298/298 [==============================] - 34s 114ms/step - loss: 3.1794 - val_loss: 3.4620\n",
      "Epoch 14/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.1385\n",
      "Epoch 00014: val_loss improved from 3.46203 to 3.44047, saving model to best_model.h5\n",
      "298/298 [==============================] - 34s 116ms/step - loss: 3.1385 - val_loss: 3.4405\n",
      "Epoch 15/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.0982\n",
      "Epoch 00015: val_loss improved from 3.44047 to 3.42468, saving model to best_model.h5\n",
      "298/298 [==============================] - 30s 100ms/step - loss: 3.0982 - val_loss: 3.4247\n",
      "Epoch 16/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.0598\n",
      "Epoch 00016: val_loss improved from 3.42468 to 3.38075, saving model to best_model.h5\n",
      "298/298 [==============================] - 31s 104ms/step - loss: 3.0598 - val_loss: 3.3807\n",
      "Epoch 17/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 3.0189\n",
      "Epoch 00017: val_loss improved from 3.38075 to 3.37520, saving model to best_model.h5\n",
      "298/298 [==============================] - 46s 156ms/step - loss: 3.0189 - val_loss: 3.3752\n",
      "Epoch 18/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.9915\n",
      "Epoch 00018: val_loss improved from 3.37520 to 3.36711, saving model to best_model.h5\n",
      "298/298 [==============================] - 44s 148ms/step - loss: 2.9915 - val_loss: 3.3671\n",
      "Epoch 19/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.9578\n",
      "Epoch 00019: val_loss improved from 3.36711 to 3.33649, saving model to best_model.h5\n",
      "298/298 [==============================] - 46s 154ms/step - loss: 2.9578 - val_loss: 3.3365\n",
      "Epoch 20/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.9341\n",
      "Epoch 00020: val_loss did not improve from 3.33649\n",
      "298/298 [==============================] - 47s 157ms/step - loss: 2.9341 - val_loss: 3.3366\n",
      "Epoch 21/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.9022\n",
      "Epoch 00021: val_loss improved from 3.33649 to 3.30462, saving model to best_model.h5\n",
      "298/298 [==============================] - 51s 172ms/step - loss: 2.9022 - val_loss: 3.3046\n",
      "Epoch 22/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.8810\n",
      "Epoch 00022: val_loss did not improve from 3.30462\n",
      "298/298 [==============================] - 58s 196ms/step - loss: 2.8810 - val_loss: 3.3093\n",
      "Epoch 23/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.8480\n",
      "Epoch 00023: val_loss improved from 3.30462 to 3.29687, saving model to best_model.h5\n",
      "298/298 [==============================] - 44s 147ms/step - loss: 2.8480 - val_loss: 3.2969\n",
      "Epoch 24/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.8262\n",
      "Epoch 00024: val_loss improved from 3.29687 to 3.26804, saving model to best_model.h5\n",
      "298/298 [==============================] - 28s 95ms/step - loss: 2.8262 - val_loss: 3.2680\n",
      "Epoch 25/50\n",
      "297/298 [============================>.] - ETA: 0s - loss: 2.8007\n",
      "Epoch 00025: val_loss improved from 3.26804 to 3.25265, saving model to best_model.h5\n",
      "298/298 [==============================] - 29s 97ms/step - loss: 2.8011 - val_loss: 3.2526\n",
      "Epoch 26/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.7806\n",
      "Epoch 00026: val_loss improved from 3.25265 to 3.25173, saving model to best_model.h5\n",
      "298/298 [==============================] - 28s 93ms/step - loss: 2.7806 - val_loss: 3.2517\n",
      "Epoch 27/50\n",
      "297/298 [============================>.] - ETA: 0s - loss: 2.7616\n",
      "Epoch 00027: val_loss improved from 3.25173 to 3.22757, saving model to best_model.h5\n",
      "298/298 [==============================] - 28s 92ms/step - loss: 2.7618 - val_loss: 3.2276\n",
      "Epoch 28/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.7377\n",
      "Epoch 00028: val_loss did not improve from 3.22757\n",
      "298/298 [==============================] - 29s 96ms/step - loss: 2.7377 - val_loss: 3.2282\n",
      "Epoch 29/50\n",
      "297/298 [============================>.] - ETA: 0s - loss: 2.7245\n",
      "Epoch 00029: val_loss improved from 3.22757 to 3.21313, saving model to best_model.h5\n",
      "298/298 [==============================] - 26s 88ms/step - loss: 2.7243 - val_loss: 3.2131\n",
      "Epoch 30/50\n",
      "297/298 [============================>.] - ETA: 0s - loss: 2.7142\n",
      "Epoch 00030: val_loss did not improve from 3.21313\n",
      "298/298 [==============================] - 28s 95ms/step - loss: 2.7138 - val_loss: 3.2265\n",
      "Epoch 31/50\n",
      "297/298 [============================>.] - ETA: 0s - loss: 2.7048\n",
      "Epoch 00031: val_loss improved from 3.21313 to 3.20403, saving model to best_model.h5\n",
      "298/298 [==============================] - 28s 94ms/step - loss: 2.7046 - val_loss: 3.2040\n",
      "Epoch 32/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.6821\n",
      "Epoch 00032: val_loss improved from 3.20403 to 3.20400, saving model to best_model.h5\n",
      "298/298 [==============================] - 27s 92ms/step - loss: 2.6821 - val_loss: 3.2040\n",
      "Epoch 33/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.6587\n",
      "Epoch 00033: val_loss improved from 3.20400 to 3.19315, saving model to best_model.h5\n",
      "298/298 [==============================] - 32s 109ms/step - loss: 2.6587 - val_loss: 3.1931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.6472\n",
      "Epoch 00034: val_loss did not improve from 3.19315\n",
      "298/298 [==============================] - 24s 79ms/step - loss: 2.6472 - val_loss: 3.1994\n",
      "Epoch 35/50\n",
      "297/298 [============================>.] - ETA: 0s - loss: 2.6338\n",
      "Epoch 00035: val_loss improved from 3.19315 to 3.18570, saving model to best_model.h5\n",
      "298/298 [==============================] - 25s 85ms/step - loss: 2.6337 - val_loss: 3.1857\n",
      "Epoch 36/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.6129\n",
      "Epoch 00036: val_loss did not improve from 3.18570\n",
      "298/298 [==============================] - 25s 85ms/step - loss: 2.6129 - val_loss: 3.1871\n",
      "Epoch 37/50\n",
      "297/298 [============================>.] - ETA: 0s - loss: 2.6086\n",
      "Epoch 00037: val_loss improved from 3.18570 to 3.17766, saving model to best_model.h5\n",
      "298/298 [==============================] - 23s 78ms/step - loss: 2.6091 - val_loss: 3.1777\n",
      "Epoch 38/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.5961\n",
      "Epoch 00038: val_loss improved from 3.17766 to 3.16916, saving model to best_model.h5\n",
      "298/298 [==============================] - 27s 90ms/step - loss: 2.5961 - val_loss: 3.1692\n",
      "Epoch 39/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.5760\n",
      "Epoch 00039: val_loss did not improve from 3.16916\n",
      "298/298 [==============================] - 26s 87ms/step - loss: 2.5760 - val_loss: 3.1752\n",
      "Epoch 40/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.5754\n",
      "Epoch 00040: val_loss did not improve from 3.16916\n",
      "298/298 [==============================] - 26s 86ms/step - loss: 2.5754 - val_loss: 3.1695\n",
      "Epoch 41/50\n",
      "297/298 [============================>.] - ETA: 0s - loss: 2.5544\n",
      "Epoch 00041: val_loss improved from 3.16916 to 3.15601, saving model to best_model.h5\n",
      "298/298 [==============================] - 26s 86ms/step - loss: 2.5546 - val_loss: 3.1560\n",
      "Epoch 42/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.5454\n",
      "Epoch 00042: val_loss improved from 3.15601 to 3.15161, saving model to best_model.h5\n",
      "298/298 [==============================] - 30s 100ms/step - loss: 2.5454 - val_loss: 3.1516\n",
      "Epoch 43/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.5416\n",
      "Epoch 00043: val_loss improved from 3.15161 to 3.14354, saving model to best_model.h5\n",
      "298/298 [==============================] - 28s 93ms/step - loss: 2.5416 - val_loss: 3.1435\n",
      "Epoch 44/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.5187\n",
      "Epoch 00044: val_loss improved from 3.14354 to 3.14230, saving model to best_model.h5\n",
      "298/298 [==============================] - 28s 92ms/step - loss: 2.5187 - val_loss: 3.1423\n",
      "Epoch 45/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.5190\n",
      "Epoch 00045: val_loss did not improve from 3.14230\n",
      "298/298 [==============================] - 29s 99ms/step - loss: 2.5190 - val_loss: 3.1560\n",
      "Epoch 46/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.5135\n",
      "Epoch 00046: val_loss did not improve from 3.14230\n",
      "298/298 [==============================] - 27s 91ms/step - loss: 2.5135 - val_loss: 3.1515\n",
      "Epoch 47/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.5038\n",
      "Epoch 00047: val_loss did not improve from 3.14230\n",
      "298/298 [==============================] - 27s 92ms/step - loss: 2.5038 - val_loss: 3.1459\n",
      "Epoch 48/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.4911\n",
      "Epoch 00048: val_loss improved from 3.14230 to 3.12794, saving model to best_model.h5\n",
      "298/298 [==============================] - 27s 89ms/step - loss: 2.4911 - val_loss: 3.1279\n",
      "Epoch 49/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.4738\n",
      "Epoch 00049: val_loss did not improve from 3.12794\n",
      "298/298 [==============================] - 26s 89ms/step - loss: 2.4738 - val_loss: 3.1321\n",
      "Epoch 50/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 2.4795\n",
      "Epoch 00050: val_loss did not improve from 3.12794\n",
      "298/298 [==============================] - 28s 92ms/step - loss: 2.4795 - val_loss: 3.1446\n"
     ]
    }
   ],
   "source": [
    "mc = kc.ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)\n",
    "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "56d25d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62, 120, 86, 86, 62, 125, 67, 6, 67, 86]\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0, len(x_val) - 1)\n",
    "\n",
    "random_music = x_val[idx]\n",
    "predictions = []\n",
    "\n",
    "for i in range(10):\n",
    "    random_music = random_music.reshape(1, n_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred = np.argmax(prob, axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0], len(random_music[0]), y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "53325b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
    "predicted_notes = [x_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cda13245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting previously generated MIDI file\n",
    "midi_file = \"music.mid\"\n",
    "Path(midi_file).unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "15a280bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output, mf):\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for offset, pattern in enumerate(prediction_output):\n",
    "        # pattern is a chord\n",
    "        if '.' in pattern or pattern.isdigit():\n",
    "            notes = []\n",
    "            \n",
    "            for current_note in pattern.split('.'):\n",
    "                new_note = Note(int(current_note))\n",
    "                new_note.storedInstrument = m21.instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = m21.instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "            \n",
    "    midi_stream = m21.stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp=mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5515b886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv7730681'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv7730681');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAAGsA/wMAAOAAQADAAIgAkDVaiACANQAAkDRaiACANAAAkCxaiACALAAAkCxaiACALAAAkDVaiACANQAAkDhaiACAOAAAkDFaiACAMQAAkDJaiACAMgAAkDFaiACAMQAAkCxaiACALACIAP8vAA==');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating MIDI file\n",
    "convert_to_midi(predicted_notes, midi_file)\n",
    "\n",
    "# Shows MIDI in player\n",
    "mf = m21.midi.MidiFile()\n",
    "mf.open(midi_file)\n",
    "mf.read()\n",
    "mf.close()\n",
    "s = m21.midi.translate.midiFileToStream(mf)\n",
    "s.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae09fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
