{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "561ad5f3",
   "metadata": {},
   "source": [
    "# Gerador de Músicas MIDI\n",
    "\n",
    "O projeto consiste em realizar um estudo no qual serão geradas músicas sem intervenção humana. Para tal, utilizou-se de músicas clássicas de Chopin como dataset e um modelo de Deep Learning.\n",
    "\n",
    "## Deep Learning - Uma breve introdução\n",
    "\n",
    "O Deep Learning é um algoritmo de Machine Learning, no qual são utilizadas redes neurais que buscam \"aprender\" de forma similar ao comportamento humano.\n",
    "\n",
    "Uma forma simples de entender é imaginar uma criança aprendendo a reconhecer objetos. A criança pode apontar para um objeto e dizer que é um carro. Dado isto, o pai/a mãe da criança pode reagir de duas maneiras: confirmar que o objeto que a criança apontou é um carro, ou falar \"Não, isto é um jarro\". Ao receber feedback suficiente, a criança começa a internalizar as características de cada objeto e cria um modelo mental que ajuda ela a reconhecer os diferentes objetos. Este modelo depende de uma comunicação efetiva entre os neurônios, transmitindo diferentes sinais e gerando este modelo complexo e hierárquico baseado no feedback recebido.\n",
    "\n",
    "O Deep Learning busca replicar este comportamento, criando um modelo no qual não é necessário entender cada etapa e decisão feita devido à complexidade e profundidade deste. Para criar o modelo, são utilizadas múltiplas camadas de \"neurônios digitais\", que vão repassando o aprendizado de camada em camada.\n",
    "\n",
    "Inicialmente, o modelo é alimentado com os dados a serem utilizados, e este tenta prever os dados, sem nenhuma intervenção. As previsões iniciais irão ser completamente (ou em sua maior parte) incorretas, mas conforme o modelo recebe feedback de suas previões, ele ajusta a comunicação entre seus \"neurônios\" até ser capaz de gerar previsões mais acuradas.\n",
    "\n",
    "Existem diversos modelos de Deep Learning, e para o desenvolvimento deste projeto, irá ser utilizado o modelo de WaveNet.\n",
    "\n",
    "## WaveNet\n",
    "\n",
    "O WaveNet é um modelo de Deep Learning para áudios \"crus\" desenvolvido pelo Google DeepMind. Ele é chamado de \"generative model\", pois tem como objetivo gerar novos samples a partir da distribuição original dos dados. Ele atua de forma similar aos modelos de linguagem utilizados em NLP.\n",
    "\n",
    "### Treinando o WaveNet\n",
    "\n",
    "Para treinar o modelo de WaveNet, utiliza-se um trecho de uma onda crua de áudio (no caso, a onda de áudio no domínio do tempo) como input. Uma onda de áudio no domínio do tempo é representada na forma de diferente valores de amplitude em diferentes intervalos de tempo, como é possível visualizar no gif abaixo.\n",
    "\n",
    "![Onda de áudio no domínio do tempo](https://jvbalen.github.io/figs/wavenet.gif)\n",
    "\n",
    "A partir da sequência de valores de amplitude, o WaveNet tenta prever qual valor de amplitude vem em seguida. Neste caso, o output depende somente das informações prévias, e não das informações que ainda serão obtidas, o que classifica este modelo como autoregressivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1f4e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System libraries\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from itertools import tee\n",
    "\n",
    "# Numpy for arrays and matplotlib for notes histogram\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Music21 library for MIDI reading and creating\n",
    "from music21.converter import parse\n",
    "from music21.note import Note\n",
    "from music21.chord import Chord\n",
    "from music21.instrument import Piano, partitionByInstrument\n",
    "from music21.stream import Stream\n",
    "from music21.midi import MidiFile\n",
    "from music21.midi.translate import midiFileToStream, TranslateWarning\n",
    "\n",
    "# sklearn to split train and test \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Filter out file warnings\n",
    "from warnings import filterwarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0afc42f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chopin = 0, Schumann = 1\n",
    "music = 1\n",
    "\n",
    "if music == 0:\n",
    "    extracted_folder_path = \"chopin/\"\n",
    "    model_name = \"model.h5\"\n",
    "    midi_file = \"music_chopin.mid\"\n",
    "    threshold = 40\n",
    "    seed = 10\n",
    "else:\n",
    "    extracted_folder_path = \"schumann/\"\n",
    "    model_name = \"model2.h5\"\n",
    "    midi_file = \"music_schumann.mid\"\n",
    "    threshold = 20\n",
    "    seed = 1\n",
    "\n",
    "# Enable threading (CPU go vroom)\n",
    "threaded = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "624bebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = False\n",
    "\n",
    "if train_model:\n",
    "    # keras to train the model\n",
    "    import keras.backend as kb\n",
    "    import keras.callbacks as kc\n",
    "    import keras.layers as kl\n",
    "    import keras.models as km\n",
    "else:\n",
    "    # keras to load the model only\n",
    "    from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c19ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(file):   \n",
    "    notes = []\n",
    "    \n",
    "    # Parsing the MIDI file\n",
    "    midi = parse(file)\n",
    "  \n",
    "    # Partition by instrument\n",
    "    partition = partitionByInstrument(midi)\n",
    "\n",
    "    # Looping over all the instruments\n",
    "    for part in partition.parts:\n",
    "        # Select only the piano\n",
    "        if 'Piano' not in str(part):\n",
    "            continue\n",
    "\n",
    "        # Checking if it is a note or a chord\n",
    "        for element in part.recurse():\n",
    "            if isinstance(element, Note):\n",
    "                notes.append(str(element.pitch))\n",
    "\n",
    "            elif isinstance(element, Chord):\n",
    "                notes.append('.'.join(map(str, element.normalOrder)))\n",
    "\n",
    "    return np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d01016",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = (p for p in Path(extracted_folder_path).rglob(\"*\") if p.is_file() and p.suffix == \".mid\")\n",
    "\n",
    "# Filter out generic instrument warning\n",
    "filterwarnings(\"default\", category=TranslateWarning)\n",
    "\n",
    "if threaded:\n",
    "    from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "    with ProcessPoolExecutor() as pool:\n",
    "        notes_list = list(pool.map(read_midi, files))\n",
    "else:\n",
    "    notes_list = list(map(read_midi, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb61e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening notes_list\n",
    "notes_f = np.concatenate(notes_list).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b999f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique notes: 247\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 319
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get frequency of each note\n",
    "unique_notes, counts = np.unique(notes_f, return_counts=True)\n",
    "\n",
    "print(f\"Number of unique notes: {len(unique_notes)}\")\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(counts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "781ce82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the most frequent notes\n",
    "frequent_notes = frozenset(unique_notes[counts >= threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d6ca8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert note to int and vice-versa\n",
    "\n",
    "# Use tee to guarantee the iterators are the same\n",
    "enum_it, rev_enum_it = tee(enumerate(sorted(list(frequent_notes))))\n",
    "\n",
    "# Helper functions\n",
    "d_int_to_note = dict(enum_it)\n",
    "int_to_note = lambda idx: d_int_to_note[idx]\n",
    "\n",
    "d_note_to_int = {note: idx for idx, note in rev_enum_it}\n",
    "note_to_int = lambda idx: d_note_to_int[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d4c821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_music = []\n",
    "\n",
    "# Adding the most frequent notes\n",
    "for notes in notes_list:\n",
    "    new_music.append([d_note_to_int[note] for note in notes if note in frequent_notes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5690ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = 32\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for note in new_music:\n",
    "    for start in range(len(note) - n_timesteps):\n",
    "        end = start + n_timesteps\n",
    "        X.append(note[start:end])  # Input\n",
    "        y.append(note[end])        # Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dbfed16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(np.array(X), np.array(y), test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3459fe2",
   "metadata": {},
   "source": [
    "### Arquitetura WaveNet\n",
    "\n",
    "Os pilares da arquitetura WaveNet estão em suas camadas de rede neural, as quais são chamadas de \"Causal Diluted 1D Convolution layers\". Mas o que significa isso? Para tal, devemos ir por partes. \n",
    "\n",
    "O primeiro conceito importante é o conceito de \"convolution\": é uma operação matemática na qual é feita uma forma de combinação entre 2 funções. Um exemplo disto é em visão computacional, onde pode ser feita uma combinação linear de uma imagem com um kernel, resultando em uma imagem que possui um filtro. Estendendo este conceito, podemos seguir para a \"1D Convolution\". Como o nome diz, ela é unidimensional, e nela o kernel/filtro se move em apenas uma direção de modo a gerar um output. A imagem abaixo mostra como um kernel (representado pelos blocos verdes) e um input (representado pelos blocos amarelos) formam um output (representado pelos blocos roxos).\n",
    "\n",
    "![1D Convolution](https://www.researchgate.net/publication/324177888/figure/fig3/AS:611641670504448@1522838146178/Calculations-involved-in-a-1D-convolution-operation.png)\n",
    "\n",
    "O output depende do tamanho do kernel, do padding, e do stride. Para este estudo, o mais importante é o padding. O padding é a ideia de possivelmente adicionar zeros à esquerda ou à direita do input de modo a gerar um output com o mesmo tamanho do input. Em 1D Convolution, existem três opções de padding:\n",
    "\n",
    "- `valid`: sem padding algum;\n",
    "- `same`: padding simétrico (mesma quantidade de zeros na esquerda e na direita);\n",
    "- `causal`: adiciona-se zeros **somente** à esquerda do input;\n",
    "\n",
    "Para nosso estudo, o padding será definido como `causal`, pois assim podemos garantir que nosso modelo depende apenas do dado atual e de dados anteriores, nunca de dados futuros (explicando assim o conceito de Causal 1D Convolution).\n",
    "\n",
    "Por fim, resta o conceito de Dilated Causal 1D Convolution. O \"Dilated\" consiste em \"furos\" ou espaços vazios entre os valores do kernel, de modo intercalado. O número de espaços depende do dilation rate do kernel, que define o chamado reception field da rede (quantidade de inputs que diretamente afetam o output). Para um kernel de tamanho `k` e um dilation rate de tamanho `d`, a nossa camada possui `d-1` espaços entre cada valor do kernel. Na imagem abaixo é possível ver um exemplo de kernel de tamanho 3x3 com dilation rate de 2 em um input de tamanho 7x7, o que gera um reception field de tamanho 5x5.\n",
    "\n",
    "![Dilated 1D Causal Convolution](https://qph.fs.quoracdn.net/main-qimg-7b3eea90fe8154efbdb14f451f6cc179-lq)\n",
    "\n",
    "Para agilizar a convergência dos dados existem também as conexões Residual e Skip, mas estas não serão utilizadas neste estudo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "074b4163",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    kb.clear_session()\n",
    "    model = km.Sequential()\n",
    "\n",
    "    model.add(kl.Embedding(len(frequent_notes), 100, input_length=32, trainable=True)) \n",
    "\n",
    "    model.add(kl.Conv1D(64, 3, activation='relu', padding='causal'))\n",
    "    model.add(kl.Dropout(0.2))\n",
    "    model.add(kl.MaxPool1D(2))\n",
    "\n",
    "    model.add(kl.Conv1D(128, 3, activation='relu', dilation_rate=2, padding='causal'))\n",
    "    model.add(kl.Dropout(0.2))\n",
    "    model.add(kl.MaxPool1D(2))\n",
    "\n",
    "    model.add(kl.Conv1D(256, 3, activation='relu', dilation_rate=4, padding='causal'))\n",
    "    model.add(kl.Dropout(0.2))\n",
    "    model.add(kl.MaxPool1D(2))\n",
    "\n",
    "    model.add(kl.GlobalMaxPool1D())\n",
    "\n",
    "    model.add(kl.Dense(256, activation='relu'))\n",
    "    model.add(kl.Dense(len(frequent_notes), activation='softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c007ea7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 18:08:33.864591: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-08 18:08:33.865435: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "if train_model:\n",
    "    mc = kc.ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "    history = model.fit(X_train, y_train, batch_size=128, epochs=30, validation_data=(X_val, y_val), verbose=1, callbacks=[mc])\n",
    "else:\n",
    "    model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3014ff90",
   "metadata": {},
   "source": [
    "### Gerando novas samples\n",
    "\n",
    "Para gerar uma música com samples anteriores, basta seguir a lógica abaixo:\n",
    "\n",
    "1. Selecionar um array com diferentes valores aleatórios de samples como ponto de início\n",
    "2. O modelo calcula a distribuição de probabilidades de todas as samples\n",
    "3. O modelo obtém a sample com maior probabilidade e coloca ela no final do array\n",
    "4. Remove-se o primeiro elemento do array e reinsere-se o novo array como input\n",
    "5. Repetem-se os passos 2 a 4 por um número `n` de iterações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56d25d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89, 77, 87, 89, 43, 89, 43, 99, 105, 99, 116, 32, 105, 105, 105]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "idx = np.random.randint(0, X_val.shape[0] - 1)\n",
    "\n",
    "samples = X_val[idx]\n",
    "predictions = []\n",
    "\n",
    "for i in range(15):\n",
    "    # Reshape to avoid incompatibility\n",
    "    samples = samples.reshape((1, n_timesteps))\n",
    "\n",
    "    prob = model.predict(samples)[0]\n",
    "    y_pred = np.argmax(prob, axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    samples = np.insert(samples[0], len(samples[0]), y_pred)\n",
    "    samples = samples[1:]\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15a280bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(predicted, file):\n",
    "    output = []\n",
    "\n",
    "    # Create Note and Chord objects\n",
    "    for offset, pattern in enumerate(predicted):\n",
    "        if '.' in pattern or pattern.isdigit():\n",
    "            notes = []\n",
    "            \n",
    "            for current_note in pattern.split('.'):\n",
    "                note = Note(int(current_note))\n",
    "                note.storedInstrument = Piano()\n",
    "                notes.append(note)\n",
    "                \n",
    "            chord = Chord(notes)\n",
    "            chord.offset = offset\n",
    "            output.append(chord)\n",
    "\n",
    "        else:\n",
    "            note = Note(pattern)\n",
    "            note.offset = offset\n",
    "            note.storedInstrument = Piano()\n",
    "            output.append(note)\n",
    "    \n",
    "    # Deleting previously generated MIDI file, if any\n",
    "    Path(file).unlink(missing_ok=True)\n",
    "    \n",
    "    midi_stream = Stream(output)\n",
    "    midi_stream.write('midi', fp=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "325e004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_player(file):\n",
    "    # Shows MIDI in player\n",
    "    # https://stackoverflow.com/questions/57021743/how-to-play-audio-inline-using-ipython-display-audio\n",
    "    mf = MidiFile()\n",
    "    mf.open(file)\n",
    "    mf.read()\n",
    "    mf.close()\n",
    "    midiFileToStream(mf).show('midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b64de98",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10e67f4",
   "metadata": {},
   "source": [
    "### Chopin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5515b886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv1203'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv1203');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAAMAA/wMAAOAAQADAAIgAkElaiACASQAAkExaiACATAAAkEdaiACARwAAkEBaAJBFWogAgEAAAIBFAACQLVqIAIAtAACQQFoAkEVaiACAQAAAgEUAAJAmWogAgCYAAJBDWgCQRVqIAIBDAACARQAAkENaAJBFWogAgEMAAIBFAACQQFqIAIBAAACQMlqIAIAyAACQQ1oAkEVaiACAQwAAgEUAAJAyWogAgDIAAJAmWogAgCYAAJAyWogAgDIAiAD/LwA=');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "midi_file = \"music_chopin.mid\"\n",
    "\n",
    "if music == 0:\n",
    "    convert_to_midi(predicitons, midi_file)\n",
    "\n",
    "show_player(midi_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f511dd7",
   "metadata": {},
   "source": [
    "### Schumann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c66213ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv1661'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv1661');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAALAA/wMAAOAAQADAAIgAkEdaiACARwAAkEVaiACARQAAkC9aiACALwAAkEdaiACARwAAkEBaAJBDWogAgEAAAIBDAACQR1qIAIBHAACQQFoAkENaiACAQAAAgEMAAJBIWogAgEgAAJBKWogAgEoAAJBIWogAgEgAAJBMWogAgEwAAJA+WgCQQ1qIAIA+AACAQwAAkEpaiACASgAAkEpaiACASgAAkEpaiACASgCIAP8vAA==');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "midi_file = \"music_schumann.mid\"\n",
    "\n",
    "if music == 1:\n",
    "    convert_to_midi(map(int_to_note, predictions), midi_file)\n",
    "\n",
    "show_player(midi_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6981ec55",
   "metadata": {},
   "source": [
    "## Conclusões\n",
    "\n",
    "O modelo foi capaz de gerar um trecho de notas musicais que remetem parcialmente a ideia de uma música. O uso de músicas de um mesmo compositor/artista e do mesmo gênero ajuda neste processo, pois não há o risco de confundir o modelo com muitos dados diferentes.\n",
    "\n",
    "No entanto, algumas notas se encontram com muita frequência, o que é presente no output. Em casos de músicas de input que não possuem muita variedade de notas/repetem muitas vezes certas notas, o modelo pode gerar algo que não soa como uma música.\n",
    "\n",
    "O ponto mais importante é que o conceito de música é subjetivo, e nem sempre utilizar as notas com maior probabilidade pode gerar uma música agradável ao ouvido humano.\n",
    "\n",
    "Para próximas iterações, pode-se aprimorar o modelo para utilizar mais de um instrumento para determinar as notas frequentes, de modo que eles interajam entre si. Pode-se também gerar alterações na lógica para considerar outros fatores além da alta probabilidade de uma nota musical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d8c523",
   "metadata": {},
   "source": [
    "## Bibliografia\n",
    "\n",
    "[Recurrent Neural Networks](https://www.slideshare.net/xavigiro/recurrent-neural-networks-2-d2l3-deep-learning-for-speech-and-language-upc-2017)  \n",
    "[WaveNet: A Generative Model for Raw Audio](https://arxiv.org/pdf/1609.03499.pdf)  \n",
    "[Keras API](https://keras.io/api/)  \n",
    "[music21 documentation](https://web.mit.edu/music21/doc/index.html)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
